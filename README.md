# Projeto-2---Valida-o-de-Hip-teses
Este projeto foi feito em duplas dentre as alunas do Laboratoria DAT002BR24 com o foco em validar hipóteses de um cliente do ramo musical.
Hoje é dia 09/04 e estou iniciando o projeto de Hipóteses.

- 09/04
    
    
    Não estou me sentindo muito focada e dissposta para ser sincera, tem sido um esforço além do normal para manter a disciplina. Sinto que esse é um processo de transição de um projeto para outro e meu cérebro ainda está fadigado; isso reflete diretamente no meu corpo.
    
    Posso pensar em tirar um tempo para mim e relaxar a mente mas tenho medo que isso me atrase, então prefiro ao menos ler o projeto, mesmo que não faça grandes avanços agora no começo, para pelo menos progredir nem que seja um passo de cada vez… como dizemos: “baby steps”.
    
    No mais, como nesse projeto, pretendo passar o alinhamento e cada ação minha diretamente para cá, creio que esta ficha será um pouco mais detalhada que a anterior.
    

Dia 10/04

- 10/04
    
    Ontem descansei a mente e senti mais disposição para focar no projeto, porém quando isso aconteceu eram 23h, então mantive os cuidados comigo para evitar cair no ciclo de estudo fora do horário do bootcamp.
    
    Hoje analisei melhor o projeto e com a mente mais tranquila o objetivo parece mais claro também.
    
    Neste novo projeto, temos o objetivo de analisar hipoteses para compreender quais caminhos existem para o nosso cliente.
    
    Nosso cliente é do ramo musical e por isso vamos analisar as seguintes hipoteses:
    
- Lista de Hipóteses
    
    > **Hipoteses**
    > 
    > - Músicas com BPM (Batidas Por Minuto) mais altos fazem mais sucesso em termos de número de streams no Spotify.
    > - As músicas mais populares no ranking do Spotify também possuem um comportamento semelhante em outras plataformas, como a Deezer.
    > - A presença de uma música em um maior número de playlists está correlacionada com um maior número de streams.
    > - Artistas com um maior número de músicas no Spotify têm mais streams.
    > - As características da música influenciam o sucesso em termos de número de streams no Spotify.
    > 
    > Você deve validar (refutar ou confirmar) essas hipóteses através da análise de dados e fornecer recomendações estratégicas com base em suas descobertas. O objetivo principal desta análise é que a gravadora e o novo artista possam tomar decisões informadas que aumentem suas chances de alcançar o “sucesso”.
    > 

[Gerenciamento projeto 2](https://www.notion.so/Gerenciamento-projeto-2-c6416568717b456f9cad5749e9137cee?pvs=21)

- Insumos
    
    > **Insumos:**
    > 
    > 
    > ### **Track*in*spotify**
    > 
    > - **track_id**: Identificador exclusivo da música. É um número inteiro de 7 dígitos que não se repete.
    > - **track_name**: Nome da música.
    > - *artist(s)_name**: Nome do(s) artista(s) da música.
    > - **artist_count**: Número de artistas que contribuíram na música.
    > - **released_year**: Ano em que a música foi lançada.
    > - **released_month**: Mês em que a música foi lançada.
    > - **released_day**: Dia do mês em que a música foi lançada.
    > - **in*spotify*playlists**: Número de listas de reprodução do Spotify em que a música está incluída
    > - **in*spotify*charts**: Presença e posição da música nas paradas do Spotify
    > - **streams**: Número total de streams no Spotify. Representa o número de vezes que a música foi ouvida.
    > 
    > ### **Track*in*competition**
    > 
    > - **track_id**: Identificador exclusivo da música. É um número inteiro de 7 dígitos que não se repete.
    > - **in*apple*playlists**: número de listas de reprodução da Apple Music em que a música está incluída.
    > - **in*apple*charts**: Presença e classificação da música nas paradas da Apple Music.
    > - **in*deezer*playlists**: Número de playlists do Deezer em que a música está incluída.
    > - **in*deezer*charts**: Presença e posição da música nas paradas da Deezer.
    > - **in*shazam*charts**: Presença e classificação da música nas paradas da Shazam.
    > 
    > ### **Track*technical*info**
    > 
    > - **track_id**: Identificador exclusivo da música. É um número inteiro de 7 dígitos que não se repete.
    > - **bpm**: Batidas por minuto, uma medida do tempo da música.
    > - **key**: Tom musical da música.
    > - **mode**: Modo de música (maior ou menor).
    > - **danceability_%**: Porcentagem que indica o quão apropriado a canção é para dançar
    > - **valence_%**: Positividade do conteúdo musical da música.
    > - **energy_%**: Nível de energia percebido da música.
    > - **acusticness_%**: Quantidade de som acústico na música.
    > - **instrumentality_%**: Quantidade de conteúdo instrumental na música.
    > - **liveness_%**: Presença de elementos de performance ao vivo.
    > - **speechiness_%**: Quantidade de palavras faladas na música.

Hoje é dia 15/04, 01:01 a.m.

- 15/04
    
    Nesta sexta-feira, minha parceira me chamou para uma chamada de video para me ajudar a seguir com o projeto para que nós ficassemos alinhadas e também para debater sobre os valores nulos e  duplicados onde a mesma estava tentando compreender uma melhor forma de lidar.
    
    Graças a sua ajuda consegui ao menos começar a trabalhar nas tabelas, porém no fim de semana trabalhei, no domingo descansei e apesar de estar mais próxima de compreender o projeto, sinto que durante algum tempo não vou conseguir trabalhar sozinha; pensei que minha dificuldade maior seria trabalhar em dupla mas na verdade será trabalhar em algo novo no momento em que me encontrio, mas… apesar de tudo, me sinto mais motivada para continuar. Se eu conseguir ignorar a auto cobrança para acompanha-la, sinto que consigo progredir e aprender.
    
    Neste momento, creio que o que me falta é ter paciência para assistir a aulas de um novo conteudo então vou dedicar algum tempo a isso, sem pressa; passos pequenos ainda são passos em direçaõa ao meu objetivo, então vou persistir.
    
    É importante ressaltar que tenho sofrido de algumas limitações quanto a maquina que estou utilizando. Até o momento, utilizo o windows 8 e ainda não posso atualizar meu computador, por isso não consigo acessar o slack por aqui, mas acesso a ferramenta pelo celular.
    
    Hoje, mais tarde, me empanharei em alcançar alguns objetivos:
    
    - [x]  Estudar sobre Big Query e SQL
    - [x]  Identificar valores nulos e duplicados na tabela
    - [ ]  (se possivel) encontrar solução para os valores citados a cima
    - [x]  Ver o conteúdo disposto pela Fernanda na nossa oficina de Job Search
    
    São 9h, iniciamos a reunião e já comuniquei minha parceira sobre o erro qu encontrei ao rodar a query no BigQuery.
    
    ![Captura de Tela (23).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/838e3f2c-5ef3-46c0-b727-2a80ed5e06b2/684349c7-f38b-4b5a-b12e-582ef5d4cbd7.png)
    
    A cima está a fórmula que minha parceira me passou para identificar os nulos. Agora vou tentar entender o porque de ela estar dando esse erro.
    
    - Já corrigi o nome da tabela e ainda da erro, então vou procurar  algum video explicativo sobre.
        - O erro era a falta do ID da tabela na Query.
    
    Utilizei a query abaixo para contar os valores nulos.
    
    ```
    SELECT
    COUNT(*)
    from `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_concorrencia`
    WHERE track_id IS NULL OR 
      in_apple_playlists IS NULL OR 
      in_apple_charts IS NULL OR 
      in_deezer_playlists IS NULL OR 
      in_deezer_charts IS NULL OR 
      in_shazam_charts IS NULL;
    ```
    

Dia 16/04
Hoje foi dia de mudança de sprint. Minhas companheiras de sala foram a Ester e a Daiane.

- 16/04
    
    Foi muito reconfortante e satisfatório, compartilhar e planejar com as minhas companheiras, o fato de sermos muito semelhantes ajudou muito a fluir a dinâmica.
    
    Hoje, vou continuar na limpeza da tabela, e me sinto muito mais tranquila e motivada para prosseguir. Ter esse esapaço para compartilhar e saber que estou segura me ajuda muito a enxergar as coisas por outro angulo e me preparar.
    
    - [x]  Encontrar todos os valores nulos
    - [x]  encontrar valores duplicados
    - [x]  (seguir com o passo a passo da Laboratoria)
    
    Valores nulos encontrados:
    
    desempenho_concorrencia: 50 - Coluna: shazam_charts
    
    desempenho_spotify: 0
    
    desempenho_tecnico: 0
    
    Para entender o processo de busca pelos nulos e ter uma precisão maior pedi ajuda ao chat GPT e esse  foi o resultado:
    
    ![Captura de Tela (25).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/a0f70e60-7ffd-4ec0-9348-61ebaf2e0fe5/d29610d6-0743-4088-8aa3-72937f141502.png)
    
    ![Captura de Tela (26).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/227ac42d-6996-429c-b163-608e50ecff13/1b285a25-aac0-4a44-b5a8-5b2917e00b43.png)
    
    ![Captura de Tela (27).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/95f5ab1d-d071-4d3f-8c4f-143a079ad5b9/b5ed7f11-b90c-4d2d-8026-0e773a602d7a.png)
    
    ![Captura de Tela (28).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/ac2dfad1-c9bd-4586-8b89-f2b3ea3b04d6/1257fbed-d144-4626-9c03-4947c0c843d6.png)
    
    ![Captura de Tela (29).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/d3aebd1e-3266-4d36-b12f-efe0d60b266b/055d6c03-09fa-480e-b9b0-7d33badf238d.png)
    
    ![Captura de Tela (30).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/85661773-0170-4237-a5ce-ad30f0eaf497/745710bc-0cbd-4376-9703-34346d76c464.png)
    
    Então apliquei a fórmula:
    
    ```
    SELECT 
    COUNTIF (track_id IS NULL) AS nulo_track_id,
    COUNTIF (in_apple_playlists IS NULL) AS nulo_in_apple_playlists,
    COUNTIF (in_apple_charts IS NULL) AS nulo_in_apple_charts,
    COUNTIF (in_deezer_playlists IS NULL) AS nulo_in_deezer_playlists,
    COUNTIF (in_deezer_charts IS NULL) AS nulo_in_deezer_charts,
    COUNTIF (in_shazam_charts IS NULL) AS  nulo_in_shazam_charts,
    from `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_concorrencia`
    ```
    
    Ela me permiter analisar e visualizar, coluna por coluna com a contagem de nulos.
    
    Após encontrar os nulos, comecei a buscar pelos valores duplicados e permaneci no chat GPT:
    
    ![Captura de Tela (31).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/800edcb7-3b6a-4bf5-9770-a691f0725c4c/86a24e9d-fc26-44ca-bfa1-e38fafd929be.png)
    
    ![Captura de Tela (32).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/71914732-7949-468f-a0ce-d1d79664e6a8/05b510ef-2e69-40f0-a607-36129fb811cd.png)
    
    ![Captura de Tela (33).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/dbc2e477-695a-455c-ab04-bda40b56eefd/10ebe63b-e30b-42dc-a555-653bb25b8f5f.png)
    
    ![Captura de Tela (34).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/2564a916-52de-410f-b8de-4c16004d7778/e95ac0c8-067b-4e05-bbb2-5e6626d63f8d.png)
    
    Após rodar a fórmula,vi que havia um erro mas não havia compreendido do que se tratava, então o encaminhei para o chat GPT:
    
    ![Captura de Tela (35).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/a0c884bd-97ff-4fb4-ae63-f9a785cb39f8/2040dade-795a-46ec-98ee-1a6cdea1dca9.png)
    
    ![Captura de Tela (36).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/ef5d188a-680f-47fc-ab35-d268ea19936c/34852189-5276-4758-82c4-0f4f7de96e75.png)
    
    ![Captura de Tela (37).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/c5bb6cd8-9364-44a8-a7ba-3c3ec9af84d0/b5a4f193-dbe7-4f94-a553-98467f4ddd08.png)
    
    Como descrito pelo chat, o erro era simples e se tratava de uma falta de sincronicidade entre os dados apresentados nas duas partes da fórmula. Para que a GROUP BY funcione, é necessário descrever a ela os mesmos dados apresentados na primeira parte.
    
    a fómula utilizada para essa consulta ficou assim:
    
    ```
    SELECT 
      track_id,
      in_apple_playlists,
      in_apple_charts,
      in_deezer_playlists,
      in_deezer_charts,
      in_shazam_charts,
      COUNT(*) AS quantidade
    FROM
      `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_concorrencia`
    GROUP BY
      track_id,
      in_apple_playlists,
      in_apple_charts,
      in_deezer_playlists,
      in_deezer_charts,
      in_shazam_charts
    HAVING
      COUNT(*) >1;
    ```
    
    Nulos encontrados em cada tabela:
    
    desempenho_concorrencia: 0
    
    desempenho_spotify: 0 (?)
    
    desempenho_tecnico: 0
    
    Em todas as consultas eu obtive zero resultados… O que isso significa? O BQ é inteligente o suficiente para comreender quais dados de fato estão se repetindo? Uma vez que sei que há dados que se repetem, mesmo que os dados que eu já tenha identiicado sejam dados que não há problema em repetir, por exemplo: um mesmo artista lançou mais de uma música de sucesso;  Ou será que essa consulta é feita de maneira linear e por isso o BQ considera que a linah precisa estar exatamente igual para ser considerada “repetida”?
    
    Vou questionar isso na sessão de dúvidas rápidas.
    
    21:57
    
    Questionei e Larissa me confirmou o que eu estava suspeitando.
    
    Como os dados estavm agrupados, eles estava fazendo uma analise linear: considerando repetidos apenas as linhas que estavam exatamente iguais, e como não temos IDs repetidos, a fórmula não puxa nenhum dado repetido.
    
    Ela também sugeriu que uma chave fosse criada (só não me recordo entre quais colunas) entre duas colunas,para que a busca ficasse mais precisa.
    
    Me recordo que Lari sugeriu a fórmula CONCAT para criar uma chave entre música e artista se não me engano. e por fim não considerar o id nessa consulta porque pode acontecer de haver IDs diferenteas mas dados repetidos.
    
    Perguntei ao chat gpt como utilizar e para que serve a formula CONCAT, essa foi a resposta dele:
    
    ![Captura de Tela (39).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/140122d2-849f-4865-a00c-9dec624492f6/9b5241f9-c045-49a2-93ef-06c1b4cbf7ad.png)
    
    ![Captura de Tela (40).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/c6c02027-3634-4513-a6ca-a42f39ce4702/b7c5163a-0ff7-4aba-beb1-d83a3c0aea2c.png)
    
    Bom, agora as fórmulas estão começando a fazer sentido para mim então com base nas respostas do chat e com a ajuda da Lari, criei uma nova tabela de dados agrupados para analisar os duplicados.
    
    O que o chat gpt me passou:
    
    ![Captura de Tela (41).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/83e4efdb-9dc7-426a-8721-d8709046622f/387078aa-095f-4474-9f1d-f07e3010e434.png)
    
    ![Captura de Tela (42).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/3fdadf54-450f-478e-a605-b002e5e31e70/2b94395a-a856-47aa-a9d3-88fc92580da7.png)
    
    ![Captura de Tela (44).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/e6504160-0760-495f-b8fa-835e6d33e9c7/d36b4b57-3582-4232-867a-82d0adffbf04.png)
    
    ![Captura de Tela (45).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/64404506-c1b0-475f-95f6-1c8d259eb87e/e92081aa-1456-47da-9c89-129aa797132c.png)
    
    ![Captura de Tela (46).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/57b1e5fb-ef96-4496-8a0f-733c74b73e44/0907edb2-c75c-4315-b69d-6a207a5d8a1a.png)
    
    A fórmula que utilizei para criar a tabela nova de dados agrupados ficou da seguinte maneira:
    
    ```
    CREATE TABLE dataset_spotify2.dados_agrupados
     AS
       SELECT
         track_id,
         CONCAT(artist_s__name, "-", track_name) AS artist_track,
         artist_count,
         released_year,
         released_month,
         released_day,
         in_spotify_playlists,
         in_spotify_charts,
         streams
          
    FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify` 
    ```
    
    Em seguida, fiz a analise dos duplicados:
    
    ```
    SELECT 
      artist_track,
       COUNT(*) AS quantidade
    FROM
      `projeto-2-hipoteses-420014.dataset_spotify2.dados_agrupados`
    GROUP BY
      artist_track
       HAVING
         COUNT(*) >1;
    ```
    
    Agora, com a tabela agrupada e os dados analisados corretamente, encontrei:
    
    desempenho_spotify: 4 (se repetem 2 vezes)
    
    desempenho_concorrencia: 0
    
    desempenho_tecnico: 0
    
    ![Captura de Tela (47).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/9b28ef64-d7d9-4ff5-87f2-2f9cf088d18c/faa497e7-652c-44f0-bf81-abf6d5f585fa.png)
    
    Minha observação é que: se no spotify temos a ocorrencia de  4 deles e todas as tabelas tem a mesma quantidade, logo, muito provável que possuam os mesmos artistas, se são os mesmos, eles se repetem a mesma quantidade nas outras planilhas também. Então, a chance de termos 4 duplicados em cada tabela, é altíssima.
    
    Uma vez que identificarmos as posições desses duplicados, identificaremos também os IDs e assim podemos excluir os IDs nas outras planilhas.
    
    - Entenda “excluir” como o sentido original de “afastar” e não com a ideia de deletar, uma vez que isso não é possível na versão gratuita, então irei criar uma tabela com os dados limpos.

Hoje é dia 18/04

- 18/04
    
    Estou agora encontrando a localização desses valores duplicados para remove-los.
    
    Perguntei ao chat GPT como encontrar a linha em que os valores duplicados estão, mas acho que não consegui explicar isso corretamente, porém ele me trouxe informações sobre essas linhas, como o ID e isso me favoreceu de certa forma, já que eu estava buscando a linha exatamente para  conseguir o ID 🤩.
    
    ![Captura de Tela (50).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/2761b72a-303f-4595-bb3a-012ec3eb0757/ed03f5a8-12bd-4d4b-9f8b-7521b0fda4cd.png)
    
    ![Captura de Tela (51).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/dfb6a552-7f1c-4b82-a7f5-0c3442091f2c/7c8c4e46-d070-44da-a14a-ac598657a529.png)
    
    ![Captura de Tela (52).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/a3bab590-e92e-48c5-9f5d-f9c8ed840942/1b47d9dd-967d-47ea-bfeb-7f99ddc4eaee.png)
    
    ![Captura de Tela (53).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/d9530690-b0b9-4acb-8fe1-c9a9e2c947b2/81b8ba71-ec8c-48f7-acad-79787bc455eb.png)
    
    ![Captura de Tela (54).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/06734f25-fb99-4fa6-bca8-2e2a764b13c9/91d0a868-b399-4687-af32-82c9565e54c3.png)
    
    ![Captura de Tela (55).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/c37f2f54-5be6-40db-96dc-d6653c7db0ff/fcf1a143-19a9-484d-ba1e-18ae4bbd0a2e.png)
    
    ![Captura de Tela (56).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/97400935-d798-4a5b-953e-a1955a1752ae/bb01fff4-fa65-4a62-96c7-d36366e018b0.png)
    
    ![Captura de Tela (57).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/48be5420-5e81-40b2-8ba8-8fe34d2d90ff/8c84b6fa-a824-498f-847c-a0b3b6b33708.png)
    
    ![Captura de Tela (58).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/5a68a530-8483-4ef4-b113-ad90aaffe189/b425172b-4b67-49f7-994f-f295cc45aec0.png)
    
    A cima está todo o processo de perguntas para ter uma fórmula mais precisa e com as informações que eu gostaria; me surpreendi pois o resultado foi ainda melhor.
    
    Por isso, a fórmula que usei foi:
    
    ```
    WITH tabela_com_numero_de_linha 
     AS (
       SELECT
       *,
       ROW_NUMBER() OVER (PARTITION BY artist_track ORDER BY artist_track) 
         AS numero_de_linha
       FROM `projeto-2-hipoteses-420014.dataset_spotify2.dados_agrupados`)
    SELECT
     *
    FROM tabela_com_numero_de_linha 
    WHERE numero_de_linha >1
    ```
    
    E esses são os resultados obtidos com a fórmula:
    
    ![Captura de Tela (48).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/bf75a2cd-5900-496b-b73b-0446d1e65806/58e9422a-df5a-413f-b5a4-9e94a8a65f4f.png)
    
    Agora preciso lidar com os valores nulos, duplicados e aproveitando os insights das reuniões, também vou lidar com os valores fora do escopo do projeto.
    
    Eu e minha parceira decidimos que nenhum dos dados citados a cima nos traria as informações que gostariamos de receber, por isso vamos excluí-los.
    
    Gostaria de acrescentar um print que tirei da acessoria com a Lari hoje que creio ser util futuramente.
    
    ![Captura de Tela (49).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/da5bf090-3108-4b35-acae-7e595ed36db9/85a38293-175b-42be-ad87-822ec370bd22.png)
    
    Substitui a tabela dados_agrupados por uma nova tabela sem os valores duplicados.
    
    Lembrar sempre que: na fórmula, a primeira tabela que indicamos, é a tabela que será substituida.
    
    Minha intenção era substituir a tabela desempenho_spotify mas entendi a fórmula de outro jeito, como se a primiera tabela fosse a que eu desejava usar para substituir a outra, ms é o oposto.
    
    É como se a nova tabela fosse apenas uma nova base para realocar as informações com outra organização.
    
    Por fim, essa foi a fórmula que usei:
    
    ```
    CREATE OR REPLACE TABLE
     `dataset_spotify2.dados_agrupados`
       AS 
         SELECT
           *
         FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify`
            WHERE track_id NOT IN ('3814670', '1119309','5080031','4967469');
    ```
    
    > Outra observação é: caso haka um erro ao colocar os valores dentro do parenteses, por exemplo: (3814670, 1119309, 5080031, 4967469) e dar erro como este:
    > 
    > 
    > No matching signature for operator IN for argument types STRING and {INT64} at [7:28]
    > 
    > significa que as colunas são tipo strings, não vão funcionar com a fórmula IN se não forem descritaas corretamente como strings.
    > 
    > No caso a cima, eu havia escrito pela primeira vez sem  ‘ ‘  , isso categorizava esses valores como inteiros (**`{INT64}`)** que não são compativeis com colunas tipo string, logo, para tornar esses valores em string, acrescentei  ‘ ‘  .
    > 
    > *Also, “string” significa “intervalo”, nesse caso.
    > 
    
    Bem, comoa tabela foi substituida e perdeu seu CONCAT, vou precisar criar outra para checar os valores duplicados, como prova real.
    
    - Correção:  eu não precisava criar outra tabela, bastava acrescentar o intervalo “CONCAT” como quando criei a tabela pela primeira vez, assim:
    
     
    
    ```
    CREATE OR REPLACE TABLE
     `dataset_spotify2.dados_agrupados`
       AS 
         SELECT
            track_id,
         CONCAT(artist_s__name," " ,"-"," ", track_name) AS artist_track,
         artist_count,
         released_year,
         released_month,
         released_day,
         in_spotify_playlists,
         in_spotify_charts,
         streams
         FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify`
            WHERE track_id NOT IN ('3814670', '1119309','5080031','4967469');
    ```
    
    Entendi que com esse comando CREATE OR REPLACE TABLE preciso acrescentar todas as modificações que fiz na tabela.
    
    Terei de seguir a mesma lógica para os valores nulos.
    
    Para substituir a tabela original com a nova, utilizei a seguinte formula:
    
    ```
    DROP TABLE dataset.spotify2.desempenho_spotify;
    
    ALTER TABLE dataset_spotify2.dados_agrupados
    RENAME TO dataset_spotifya2.desempenho_spotify;
    ```
    
    Como ela substituiu a tabela mas não substituiu o nome, reforcei a fórmula:
    
    ```
    ALTER TABLE dataset_spotify2.dados_agrupados
    RENAME TO desempenho_spotify;
    ```
    
    Para remover os valores nulos e fora do escopo do projeto, utilizei a formula:
    
    ```
    CREATE OR REPLACE TABLE
     `dataset_spotify2.desempenho_concorrencia`
       AS 
         SELECT
            track_id,
            in_apple_playlists,
            in_apple_charts,
            in_deezer_playlists,
            in_deezer_charts,
         FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_concorrencia`
            WHERE track_id NOT IN ('3814670', '1119309','5080031','4967469');
    ```
    
    ```
    CREATE OR REPLACE TABLE
     `dataset_spotify2.desempenho_tecnico`
       AS 
         SELECT
            track_id,
            bpm,
            danceability__,
            valence__,
            energy__,
            acousticness__,
            instrumentalness__,
            liveness__,
            speechiness__
         FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_tecnico`
            WHERE track_id NOT IN ('3814670', '1119309','5080031','4967469');
    ```
    
    Agora que esses dados foram removidos, vou descansar.
    
    São 2h15 da manhã e senti que finlamente voltei para os trilhos!
    
    Consegui terminar a semana de maneira produtiva, sem estresse, chat gpt virou meu grande amigo, consegui entender os insights na turma e amei conhecer a ferramenta BigQuery!
    
    Sei que a entendi pois ontem mostrei ao meu amigo que estuda T.I. o que estava fazendo; ele não conhecia essa ferramenta então expliquei a ele como funcionava, ai percebi que de fato, eu tinha aprendido algo e estava entendendo o que estava fazendo.
    
    Finalizo  essa noite muito feliz!
    
    Amanhã irei me reunir com minha parceira e vamos falar sobre o ponto em que estamos no projeto.
    

Hoje é dia 22/04

- 22/04
    
    Estou na reunição e vou preencher a tabela cronograma que minha parceira me mandou.
    
    No dia em que me reuni com a Nath, vi suas querys e achei muito mais simples/faceis de aplicar, gostei disso. Nesse momento não vou reformular minhas tabelas, mas caso precise criar outra e remover colunas, vou tentar a da  minha parceira…
    
    > SELECT
       * 
    EXCEPT (track_name,artist_s__name), 
    FROM projeto-hipoteses.Dataset_spotify.Desempenho_Spotify_semcaracteres
    > 
    
    Hoje foi um daqueles dias onde lutei para ter foco e infelizmente só consegui colocar tudo em prática agora.
    
    Minhas sessão de reflexão ficou para quarta-feira (24/04) ás 11h.
    
    Terminei o módulo 1 de Job Preparation e agora vou seguir com  o projeto.
    
    Minha parceiras me informou que ter uma coluna concatenada pode dificultar na hora de procurar alguns valores para contestar as hipoteses então o melhor seria separar a coluna novamente.
    
    Eu havia unido track_name e artist_s__name para “artist_track” na intenção de criar uma chave unica para pesquisar valores duplicados, mas não havia pensado em outra maneira de analisar até então.
    
    Como agora já substitui e apaguei a tabela original do spotify, terei de apagar a atual e reupar a original, realizando novamente a limpeza dela.
    
    - SPLIT
        
        ```
        SELECT 
         SPLIT(artist_track, ",") [OFFSET(0)] AS artist_name,
         SPLIT(artist_track, ",") [OFFSET(0)] AS track_name 
        FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify` 
        ```
        
        ![Captura de Tela (63).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/c46f22ac-934a-45a9-ab02-74e2ab469d79/e7d8e027-90e3-4c79-a380-5f796f60e9b1.png)
        
        ![Captura de Tela (64).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/3a07d77f-d753-4b7d-878d-1e867a2a960d/73e3652b-9937-4a5b-a4f1-24681882d16b.png)
        
        ![Captura de Tela (65).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/7d2623cd-f993-4c29-9328-bfe655559419/7052e46d-52ad-40d9-b6f5-53c3f11eb5e6.png)
        
    
    Caso eu não tivesse apagado, poderia usar a fórmula “SPLIT”, mas também há outro detalhe: para que o BQ entenda que exitem dois valores ali na coluna, eu teria de separa-los por “,” não por”_”.
    
    Recriei a tabela já limpa sem os duplicados e sem concatenar:
    
    ```
    CREATE OR REPLACE TABLE
     `dataset_spotify2.desempenho_spotify`
       AS 
         SELECT
            track_id,
           artist_s__name,
           track_name,
           artist_count,
           released_year,
           released_month,
           released_day,
           in_spotify_playlists,
           in_spotify_charts,
           streams
         FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify`
            WHERE track_id NOT IN ('3814670', '1119309','5080031','4967469');
    ```
    
    Analisar  e substituir caracteres especiais de uma string:
    
    ```
    SELECT
      track_name,
      REGEXP_REPLACE(track_name, r'[^\w\s]', " ") AS track_name_limpo
    
    FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify` 
    ```
    
    Percebi que inevitavelmente,  toda mudança que eu desejar fazer, terei de acrescentar ao código enquanto em outra aba faço apenas a consulta.
    
    Tentei criar outra tabela sem acrescentar as colunas que deveriam estar la e precisei upar a tabela spotify mais uma vez :’) 
    
    Por fim, a fórmula ficou assim:
    
    ```
    ---nova tabela criada spotify
    CREATE OR REPLACE TABLE
     `dataset_spotify2.desempenho_spotify`
       AS 
         SELECT
            track_id,
            ---tratamento variaveis categoricas
           REGEXP_REPLACE(artist_s__name, r'[^\w\s]', " ") AS artist_s__name_limpo,
           REGEXP_REPLACE(track_name, r'[^\w\s]', " ") AS track_name_limpo,
           artist_count,
           released_year,
           released_month,
           released_day,
           in_spotify_playlists,
           in_spotify_charts,
           streams
         FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify`
         ---tratamento dados duplicados
            WHERE track_id NOT IN ('3814670', '1119309','5080031','4967469');
    
    ```
    

Hoje é dia 23/04

- 23/04
    
    Refiz a fórmula atualizada com base no que minha companheira mostrou e também vi outras meninas acrescentando essa correção para deixar a limpeza mais assertiva e não causar problemas posteriormente:
    
    ```
    ---nova tabela criada spotify
    CREATE OR REPLACE TABLE
     `dataset_spotify2.desempenho_spotify`
       AS 
         SELECT
            track_id,
            ---tratamento variaveis categoricas
           REGEXP_REPLACE(artist_s__name_limpo, r'[^a-zA-Z0-9]' , " ") AS artist_s__name_limpo,
           REGEXP_REPLACE(track_name_limpo,  r'[^a-zA-Z0-9]', " ") AS track_name_limpo,
           artist_count,
           released_year,
           released_month,
           released_day,
           in_spotify_playlists,
           in_spotify_charts,
           streams
         FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify`
         ---tratamento dados duplicados
            WHERE track_id NOT IN ('3814670', '1119309','5080031','4967469');
    
    ```
    
    > r'[^a-zA-Z0-9]' representa o código para selecionar e substituir caracteres especiais.
    > 
    
    <aside>
    💡 Esse é o momento de analisar nossas variáveis.
    Temos variáveis categóricas (artist_s__name_limpo e track_name_limpo) que representam dados qualitativos e temos variáveis numéricas (todas as outras variáveis) que representam, como o próprio nome sugere, variáveis que são descritas através de números.
    
    - A intenção dessa análise é encontrar quais valores não fazem parte dessas variavies, por exemplo: na análise anterior tivemos de remover os caracteres especiais pois eles não se encaixam nesse escopo, agora, nas numéricas temos de identificar quais valores não possuem apenas números.
    
    </aside>
    
    Para limpar os valores discrepantes em streams eu acrescentei a fórmula:
    
    SAFE_CAST(streams AS INT64) AS streams_limpo 
    
    > SAFE_CAST diferente do CAST vai pegar os valores que ele não consegue ler e vai substituir por nulos.
    > 
    
    A fórmula da tabela ficou da seguinte maneira:
    
    ```
    ---nova tabela criada spotify
    CREATE OR REPLACE TABLE
     `dataset_spotify2.desempenho_spotify`
       AS 
         SELECT
            track_id,
            ---tratamento variaveis categoricas
           REGEXP_REPLACE(artist_s__name_limpo, r'[^a-zA-Z0-9]' , " ") AS artist_s__name_limpo,
           REGEXP_REPLACE(track_name_limpo,  r'[^a-zA-Z0-9]', " ") AS track_name_limpo,
           artist_count,
           released_year,
           released_month,
           released_day,
           in_spotify_playlists,
           in_spotify_charts,
           ---tratamento variveis numericas
           SAFE_CAST(streams AS INT64) AS streams_limpo
         FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify`
         ---tratamento dados duplicados
            WHERE track_id NOT IN ('3814670', '1119309','5080031','4967469');
    
    ```
    
    Consulta de variáveis numéricas com MAX, MIN e AVG:
    
    ```
    SELECT
      MAX(streams_limpo),
      MIN(streams_limpo),
      AVG(streams_limpo),
      MAX(artist_count),
      MIN(artist_count),
      AVG(artist_count),
      MAX(released_year),
      MIN(released_year),
      AVG(released_year),
      MAX(released_month),
      MIN(released_month),
      AVG(released_month),
      MAX(released_day),
      MIN (released_day),
      AVG (released_day),
      MAX (in_spotify_playlists),
      MIN (in_spotify_playlists),
      AVG (in_spotify_playlists),
      MAX (in_spotify_charts),
      MIN (in_spotify_charts),
      AVG (in_spotify_charts),
    FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify` 
    ```
    
    ```
    SELECT
     MAX(in_apple_playlists),
     MIN(in_apple_playlists),
     AVG(in_apple_playlists),
     MAX(in_apple_charts),
     MIN(in_apple_charts),
     AVG(in_apple_charts),
     MAX(in_deezer_playlists),
     MIN(in_deezer_playlists),
     AVG(in_deezer_playlists),
     MAX(in_deezer_charts),
     MIN(in_deezer_charts),
     AVG(in_deezer_charts),
    FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_concorrencia` 
    ```
    
    ```
    SELECT
     MAX(bpm),
     MIN(bpm),
     AVG(bpm),
     MAX(danceability__),
     MIN(danceability__),
     AVG(danceability__),
     MAX(valence__),
     MIN(valence__),
     AVG(valence__),
     MAX(energy__),
     MIN(energy__),
     AVG(energy__),
     MAX(acousticness__),
     MIN(acousticness__),
     AVG(acousticness__),
     MAX(instrumentalness__),
     MIN(instrumentalness__),
     AVG(instrumentalness__),
     MAX(liveness__),
     MIN(liveness__),
     AVG(liveness__),
     MAX(speechiness__),
     MIN(speechiness__),
     AVG(speechiness__),
    FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_tecnico`
    ```
    

Hoje é dia 25/04

- 25/04
    
    Ontem, dia 24/04 eu tirei o dia para descansar e regular meu sono que estava me atrapalhando bastante pois decidi trabalhar no projeto no fim de semana também.
    
    Então hoje, mais descansada (dormi das 22h as 8h glória!) vou trabalhar no projeto e me encontrar com a minha dupla.
    
    Minhas metas de hoje:
    
    - [x]  Criar novas variáveis;
    - [ ]  Unir tabelas;
    - [ ]  Construir tabelas auxiliares
    
    Para variavel de data:
    
    SELECT
      *,
      DATE (released_year,released_month,released_day) AS data_de_lancamento
    FROM `projeto-hipoteses.Dataset_spotify.Desempenho_Spotify_Limpos`
    
    Pelo que entendi, vou ter que unir as tabelas antes de criar a variavel “total  de participação em streams”, já que essa é a maneira mais prática de fazer isso.
    

Dia 26/04

- 26/04
    - [x]  Unir tabelas;
    
    Fórmula utilizada para unir tabelas:
    
    ```
    SELECT
      T1.*,
      T2.in_apple_playlists,
      T2.in_apple_charts
      T2.in_deezer_playlists,
      T2.in_deezer_charts
    FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify` AS T1
    JOIN `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_concorrencia` AS T2
    ON T1.track_id=T2.track_id;
    ```
    
    CORREÇÃO:
    
    ```
    ---nova tabela criada spotify
    CREATE OR REPLACE TABLE
     `dataset_spotify2.desempenho_spotify`
       AS 
         SELECT
         --- união de tabelas
           T1.track_id,
           T1.artist_s__name_limpo,
           T1.track_name_limpo,
           T1.artist_count,
           T1.data_de_lancamento,
           T1.in_spotify_playlists,
           T1.in_spotify_charts,
           T2.in_apple_playlists,
           T2.in_apple_charts,
           T2.in_deezer_playlists,
           T2.in_deezer_charts,
           T1.streams_limpo
    FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify` AS T1
    
    JOIN `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_concorrencia` AS T2
    
    ON T1.track_id=T2.track_id;
    ```
    
    União + Nova variável de participação:
    
    ```
    ---nova tabela criada spotify
    CREATE OR REPLACE TABLE
     `dataset_spotify2.desempenho_spotify`
       AS 
         SELECT
            track_id,
           artist_s__name_limpo,
           track_name_limpo,
           artist_count,
           in_spotify_playlists,
           in_spotify_charts,
           in_apple_playlists,
           in_apple_charts,
           in_deezer_playlists,
           in_deezer_charts,
           ---nova variavel de total de participação por playlists
           CAST
             (CONCAT (in_spotify_playlists,in_spotify_charts,in_apple_playlists,in_apple_charts,in_deezer_playlists,in_deezer_charts) AS INT64) AS total_de_part_playlists,
           streams_limpo
         FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify`
         ---tratamento dados duplicados
            WHERE track_id NOT IN ('3814670', '1119309','5080031','4967469');
    
    ```
    

Dia 01/05

- 01/05
    
    Nos dias 29 e 30/04 eu foquei no Job Preparation e na mudança de Sprit pois na ultima semana não consegui dar a devida atenção para essas áreas, principalmente o Job Prep.
    
    Fiz o currículo no modelo ATS, até o fim de semana pretendo fazer o currículo visual e agendar minha mentoria; se for possível, também gostaria de melhorar o meu perfi do linkedin de acordo com o perfil Tech.
    
    Agora no dia 01/05, é 1h36 a.m. e pretendo fazer as tabelas auxiliares, em seguida iniciar a análise exploratória.
    
    Fiz a tabela temporária através da fórmula:
    
    ```jsx
    WITH musicas_por_artistas_solo AS (
      SELECT
        artist_s__name_limpo,
        COUNT (*) AS total_musicas
        FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify`
        GROUP BY artist_s__name_limpo
        )
    SELECT *
    FROM musicas_por_artistas_solo
    ```
    
    Agora, vou iniciar a análise exploratória:
    
    Devido as limitações de sistema do meu computador, não poderei baixar o Power BI por enquanto, por isso, vou usa-lo na internet mesmo.
    

Dia 06/05

- 06/05
    
    Finalmente consegui retornar para o projeto.
    
    formatei o computador e agora, a única coisa que preciso me preocupar é o armazenamento/lentidão kkk
    
    Agora, preciso trabalhar em cima no projeto para alcançar minha companheira; mesmo sabendo que não há problema em levar mais tempo, isso não depende só de mim.
    
    Estou no Power BI agrupando variáveis categóricas; hoje vai ser o dia para extrair o máximo possível da produtividade, além do projeto, preciso preparar a segunda parte do Job Prep, então vamos as metas de hoje:
    
    - [x]  Agrupar variáveis categóricas;
    - [x]  Visualizar variáveis categóricas;
    - [x]  Aplicar medidas de tendência central;
    - [x]  LinkedIn Job Preparation;
    - [x]  Agendar entrevista
    
    Preciso também gerenciar meu sono… não está nada positivo.
    
    Bem, como tenho pouco tempo, decidi fazer o mínimo de variáveis categóricas possível.
    
    Minha intenção era chegar ao marco 3 nesse projeto, quero me desenvolver muito mais do que já consegui e infelizmente, nesse momento tenho que considerar como um grupo e não como indivíduo… mas me tranquiliza lembrar que posso retornar a cada projeto e fazer os marcos seguintes, testando novas analises.
    
    Dei  preferência para o agrupamento que me permitiria validar as hipóteses posteriormente: Artistas com mais músicas.
    

Dia 07/05

- 07/05
    
    Hoje o dia foi dedicado ao planejamento!
    
    Este mês me provou o quanto um BOM planejamento junto ao foco é importante… Nunca senti tanta falta de controle para administrar um projeto… e olha que pensei que meu maior desafio seria me adaptar a quem fosse minha dupla, felizmente, meu relacionamento com minha parceira é muito melhor do que eu poderia esperar e finalmente coloquei um planejamento disciplinado em prático.
    
    Fiz um quadro de planejamento com as metas do bootcamp, projeto e etc, sem muita coisa, apenas com o que me impulsiona.
    
    Em breve vou fazer um das minhas tarefas pessoais, mas como minha prioridade é terminar o projeto no prazo, vou focar primeiro nele e depois realizar as atividades que me propus.
    
    Atualmente estou em “ver distribuição” com Phyton e confesso que não entendi e como passei o dia planejando (que era o foco) já deixei pré-iniciado e amanhã vou pedir ajuda as meninas.
    
    Também comuniquei minha parceira em qual ponto estou e pedi ajuda para prosseguir, na quinta nos reuniremos e iremos trabalhar no projeto.
    

Dia 08/05

- 08/05
    
    Não consegui expressar minha dúvida para as meninas do meu grupo de aprendizagem colaborativa hoje, mas isso foi devido o  meu atraso, então perguntei ao chat GPT qual era o erro no código python apresentado e ele me trouxe a resposta.
    
    ![Captura de Tela (5).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/8d625ff5-4a3f-4479-b1eb-98ba0636ff8b/c25947bf-9c33-4402-9dbf-1ffbb022df9f.png)
    
    ![Captura de Tela (6).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/5e6b7421-dd42-4584-aba3-377317e302ec/bb32c7cd-f6af-495b-9bc4-93382d72a378.png)
    
    ![Captura de Tela (7).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7bb4ff67-878c-4a87-9c1c-f64dc250cae1/6f5c51dc-c62f-4e24-84a8-a2cb7cd1d84d/fad0785b-3da8-4ad5-bb0d-c445bba4df0f.png)
    
    Consegui compreender um pouco melhor porém, ao prosseguir para a visualização do comportamento ao longo dos anos, percebi que havia esquecido de incluir a coluna de data de lançamento na tabela do bigquery :’) então precisei criar uma outra tabela somente com a data de lançamento e o id dentro do conjunto, de maneira que não afetasse o restante da análise.
    
    Consegui importar e visualizar o comportamento através do gráfico de linhas.
    
    Agora, vou respeitar meu horário para dormir melhor e conseguir manter o foco pois amanhã eu e minha dupla vamos nos reunir e trabalhar para chegar na reta final.
    
    Vou também usar esse espaço de hoje até ás 23h para montar meu cronograma pessoal.
    

Dia 13/05

- 13/05
    
    Hoje vou fazer um resumo dos últimos dias para explicar como cheguei até o ponto em que estou.
    
    Sendo sincera, não estou contente com a ultima semana, pois ao invés de sentir que aprendi e absorvi conhecimento como nas outras, sinto que só fui colocando fórmulas e realizando ações sem entender muito bem o motivo delas porque queria entregar  o projeto no tempo que também ficasse bom para a minha parceira. Terminei esse sprint com a visualização de que para esse projeto eu precisava de mais tempo para compreender de fato o que eu estava fazendo.
    
    Sinto que talvez, se tivesse exigido de mim nas primeiras semanas como fiz nessas ultimas, teria ganhado tempo para compreender o final… enfim, creio que tudo ficará mais claro no próximo projeto, só quero conseguir finaliza-lo.
    
    Mesmo não relatando, trabalhei nos ultimos dias nele, grande parte no Power BI, atualmente, estou na aplicação da segmentação.
    
    Em alguns momentos precisei retornar no BigQuery, um deles foi para criar uma nova tabela que tivesse a data de lançamento pois eu havia esquecido de inclui-la na tabela nova do spotify haha! Mas agora está feita, também precisei unir as tabelas para fazer o calculo de correlação; vou deixar algumas fórmulas aqui para o meu futuro eu.
    
- quartil fórmula
    
    ```
    WITH Quartiles AS(
      SELECT
       bpm,acousticness__,danceability__,energy__,instrumentalness__,liveness__,speechiness__,valence__,
        NTILE(4) OVER (ORDER BY bpm) AS quartile_bpm,
        NTILE(4) OVER (ORDER BY acousticness__) AS quartile_acousticness__,
        NTILE(4) OVER (ORDER BY danceability__) AS quartile_danceability__,
        NTILE(4) OVER (ORDER BY energy__) AS quartile_energy__,
        NTILE(4) OVER (ORDER BY instrumentalness__) AS quartile_instrumentalness__,
        NTILE(4) OVER (ORDER BY liveness__) AS quartile_liveness__,
        NTILE(4) OVER (ORDER BY speechiness__) AS quartile_speechiness__,
        NTILE(4) OVER (ORDER BY speechiness__) AS quartile_valence__
        ,
        NTILE(4) OVER (ORDER BY bpm) as  Quartile_bpm_
      FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_tecnico`
    )
    SELECT
     a.*,
    Quartiles.quartile_bpm_, quartile_acousticness__,quartile_danceability__,quartile_energy__,quartile_instrumentalness__,quartile_liveness__,quartile_speechiness__,quartile_valence__,
      IF(quartiles.quartile_bpm =4, 'alto','baixo') AS classificacao_quartil_bpm,
       IF(quartiles.quartile_acousticness__ =4, 'alto','baixo') AS classificacao_quartil_acousticness__,
       IF(quartiles.quartile_danceability__ = 4, 'alto', 'baixo') AS classificacao_quartil_danceability__,
      IF(quartiles.quartile_energy__ >= 4, 'alto', 'baixo') AS classificacao_quartil_energy__,
      IF(quartiles.quartile_instrumentalness__ >= 4, 'alto','baixo') AS classificacao_quartil_instrumentalness__,
      IF(quartiles.quartile_liveness__ >= 4, 'alto', 'baixo') AS classificacao_quartil_liveness__,
      IF(quartiles.quartile_speechiness__ >= 4, 'alto','baixo') AS classificacao_quartile_speechiness__,
       IF(quartiles.quartile_valence__ >= 4, 'alto','baixo') AS classificacao_quartile_valence__,
    FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_tecnico` a
    
    LEFT JOIN Quartiles
    
    ON  a.bpm=Quartiles.bpm
    
    ```
    
    <aside>
    💡 Importante ressaltar que além do quartil, aqui há também uma fórmula para criar categorias como “alto” e “ baixo”.
    
    </aside>
    
- união de colunas na tabela
    
    ```
    CREATE OR REPLACE TABLE
     `dataset_spotify2.desempenho_spotify`
       AS 
         SELECT
           t1.*,
           t2.bpm,
           t2.danceability__,
           t2.energy__
      
        FROM `dataset_spotify2.desempenho_spotify` AS t1
     
        JOIN `dataset_spotify2.desempenho_tecnico` AS t2
    
         ON t1.track_id=t2.track_id
    ```
    
- correlação fórmula
    
    ```
    SELECT
      CORR(streams_limpo, total_de_part_playlists) AS correlacao_valor_TTPP,
      CORR(streams_limpo, danceability__) AS correlacao_dance
    FROM `projeto-2-hipoteses-420014.dataset_spotify2.desempenho_spotify`
    ```
    
- 13/05
    
    Estou buscando uma fórmula de segmentar os dados que fique facil de manusear e compreender.
    
    Acredito que usar o Power BI e o Big Query juntos pode me ajudar.
    
    Percebi que o que estava me atrapalhando era utilizar a variável errada haha, mas ao perguntar no grupo da LAB a Ana veio para me ajudar então percebi esse erro.
    
    Agora com as análises feitas, apesar de não ter extraido o maximo que gostaria e planejava deste projeto, está tudo bem! Consegui finalizar essa etapa agora basta validar as hipoteses e trazer um dashboard e uma analise coesa e que se encaixe no que foi pedido, afinal, este era o objetivo; se eu conseguir extrair uma boa analise, ao menos significa que consegui realizar as tarefas corretamente e com calma, mais para frente, poderei me aprofundar e entender melhor  o que fiz e como posso aprimorar.
    
    Hoje também fiz a mentoria com a recrutadora e fiquei muito contente com os resultados.
    

Dia 14/05

- 14/05
    - [x]  Planejar ultimo sprint
    - [x]  validar hipoteses
    - [ ]  tirar duvidas sobre modulo 3 job prep
    
    Hora de validar as hipótese:
    
    - Músicas com BPM (Batidas Por Minuto) mais altos fazem mais sucesso em termos de número de streams no Spotify.
    
    R: O artista com maior número de streams no spotify é Pharell Williams e suas musicas apresentam um bpm baixo, logo, essa hipotese está incorreta; porém, se considerarmos quem tem mais streams no total, teremos The weekend e suas musicas tem o bpm BAIXO.
    
    Talvez, principalmente para o publico do spotify, as musicas de preferencia sejam com um BPM menor em consideração as outras, tendo em vista que The weekend está no topo, mas loGo atras temos mais 3 artistas/musicas com bpm baixo como lideres do rancking. 
    
    - As músicas mais populares no ranking do Spotify também possuem um comportamento semelhante em outras plataformas, como a Deezer.
    
    R: Deezer apresenta um comportamento semelhante ao spotify tendo também pharrell williams como artista mias popular em streams, o mesmo não acontece para a Apple;
    
    já em relação a música, Pharrell Williams está em primeiro no spotify, smells like teen spirit no deezer, bliding lights no apple music.
    
    - A presença de uma música em um maior número de playlists está correlacionada com um maior número de streams.
    
    R: Tendo Blinding Lights em primeira posição em ambos, poderiamos dizer que sim, mas precisamos considerar o quadro todo:
    
    Nas posições seguintes, não encontramos as mesmas músicas para as duas categorias; só encontramos uma música que possua o mesmo destaque quando chegamos na 6ª ou 7ª posição e ainda sim não possuem a mesma visibilidade que blinding lights
    
    - Artistas com um maior número de músicas no Spotify têm mais streams.
    
    R: Incorreto, Taylor Swift possui ao todo 34 músicas no spotify mas não possui uma posição de destaque nos streams.
    
    - As características da música influenciam o sucesso em termos de número de streams no Spotify.
    
    R: Pharrell Williams sendo o artista com maior destaque no spotify  em questão de playlists com a música “Get lucky (poart. Daft Punk) tem valores baixos desde o BPM até a energia da música, o que pode representar uma música mais agradavél por ser tranquila e envolvente, já em relação ao número de streams, já The weekend, sendo destaque com Blinding Lights, possui as mesmas cracteristicas: são música que buscam envolver o ouvinte na melodia, com uma necessidade em apreciar a música mesmo que não a dance e ambas tem, grande destaque, logo: sim, as caracteristicas influenciam muito no sucesso que o artista terá nos streams e nas playlists do spotify.
    
    Você deve validar (refutar ou confirmar) essas hipóteses através da análise de dados e fornecer recomendações estratégicas com base em suas descobertas. O objetivo principal desta análise é que a gravadora e o novo artista possam tomar decisões informadas que aumentem suas chances de alcançar o “sucesso”.
    

Dia 17/05

- 17/05
    
    Depois de dois dias com uma infecção, sem conseguir dormir direito ou comparecer nas reuniões da LAB, consegui hoje de madrugada terminar o projeto dentro do prazo, agora basta montar uma apresentação e entregar o video explicando a analise.
    
    Aqui está uma cópia da pasta do arquivo para análise:
    
    [Projeto 2: Analise de Hipóteses - Google Drive](https://drive.google.com/drive/folders/13qzChnNp2OjoWz790yJvjNHGz8eLAn5R?usp=drive_link)
    
    Amanhã (hoje) durante a tarde, desenvolverei a apresentação e acrescentarei o video aqui também.
    
    Video da apresentação:
    
    https://www.loom.com/share/6d6a41f09d7742fcba785b0eddb89143?sid=00bca7e6-7e61-4224-ab58-06e581528ded
